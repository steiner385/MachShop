# Logstash Pipeline Configuration
# Phase 2, Task 2.2: Log Processing Pipeline for MES Microservices

input {
  # TCP input for direct log shipping
  tcp {
    port => 5000
    codec => json
    tags => ["tcp"]
  }

  # Beats input for Filebeat/Metricbeat
  beats {
    port => 5044
    tags => ["beats"]
  }

  # For Docker logs (if using Docker logging driver)
  # docker logs get sent as JSON
  http {
    port => 8080
    codec => json
    tags => ["http"]
  }
}

filter {
  # Parse JSON logs
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
      target => "parsed"
    }
  }

  # Extract service name from container name or tags
  if [container_name] {
    grok {
      match => { "container_name" => "mes-%{DATA:service_name}" }
    }
  }

  # Add microservice context
  if [service_name] == "auth-service" {
    mutate {
      add_field => { "service_port" => "3008" }
      add_field => { "service_category" => "authentication" }
    }
  }
  else if [service_name] == "work-order-service" {
    mutate {
      add_field => { "service_port" => "3009" }
      add_field => { "service_category" => "production" }
    }
  }
  else if [service_name] == "quality-service" {
    mutate {
      add_field => { "service_port" => "3010" }
      add_field => { "service_category" => "quality" }
    }
  }
  else if [service_name] == "material-service" {
    mutate {
      add_field => { "service_port" => "3011" }
      add_field => { "service_category" => "material" }
    }
  }
  else if [service_name] == "traceability-service" {
    mutate {
      add_field => { "service_port" => "3012" }
      add_field => { "service_category" => "traceability" }
    }
  }
  else if [service_name] == "resource-service" {
    mutate {
      add_field => { "service_port" => "3013" }
      add_field => { "service_category" => "resources" }
    }
  }
  else if [service_name] == "reporting-service" {
    mutate {
      add_field => { "service_port" => "3014" }
      add_field => { "service_category" => "analytics" }
    }
  }
  else if [service_name] == "integration-service" {
    mutate {
      add_field => { "service_port" => "3015" }
      add_field => { "service_category" => "integration" }
    }
  }

  # Parse log levels
  if [level] {
    mutate {
      lowercase => [ "level" ]
    }
  }

  # Extract HTTP request info if present
  if [parsed][req] {
    mutate {
      add_field => {
        "http_method" => "%{[parsed][req][method]}"
        "http_url" => "%{[parsed][req][url]}"
        "http_status" => "%{[parsed][res][statusCode]}"
      }
    }
  }

  # Add timestamp
  date {
    match => [ "timestamp", "ISO8601", "UNIX_MS" ]
    target => "@timestamp"
  }

  # Extract trace ID for distributed tracing correlation
  if [trace_id] or [traceId] or [x-request-id] {
    mutate {
      add_field => { "correlation_id" => "%{[trace_id]}" }
    }
  }

  # Tag errors for easy filtering
  if [level] =~ /error|fatal/ {
    mutate {
      add_tag => [ "error" ]
    }
  }

  # Tag warnings
  if [level] =~ /warn/ {
    mutate {
      add_tag => [ "warning" ]
    }
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "mes-logs-%{+YYYY.MM.dd}"
    document_type => "_doc"
  }

  # Output to console for debugging (can be disabled in production)
  stdout {
    codec => rubydebug
  }

  # Separate index for error logs
  if "error" in [tags] {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "mes-errors-%{+YYYY.MM.dd}"
      document_type => "_doc"
    }
  }

  # Separate index for audit logs
  if [parsed][audit] == true or "audit" in [tags] {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "mes-audit-%{+YYYY.MM.dd}"
      document_type => "_doc"
    }
  }
}
